{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori-Algorithmus\n",
    "Implementieren Sie den Apriori-Algorithmus zum Finden häufiger Item Sets bei einer gegebenen Menge von Transaktionen. Nutzen Sie das gegebene Grundgerüst und beachten Sie folgende Anforderungen:\n",
    "- Hinweis: Achten Sie besonders bei der Apriori Kandidatengenerierung darauf, dass Sie den Support möglichst effizient und nur von möglichst wenigen Itemsets berechnen.\n",
    "- Die Ausgabe des Programms ist eine Liste aller Frequent Item Sets zusammen mit ihrem jeweiligen Support. Diese sollen in einer sinnvollen Datenstruktur zurückgegeben werden.\n",
    "- Die Implementierung der Itemsets als Hashbäume müssen Sie NICHT umsetzen.\n",
    "- Sie können Ihr Programm zum Beispiel auf dem Datensatz warenkorb.csv testen.\n",
    "- Ihre Implementierung können Sie bis zum 15.12.2023 23:59 im Moodle abgeben.\n",
    "- Sie dürfen das externe Paket numpy verwenden. Aus dem Standard-Paket collections sollte vor allen Dingen die Klasse *Counter* für Sie hilfreich sein.\n",
    "\n",
    "## Zusatzaufgabe für 6 ECTS:\n",
    "**Hinweis**: Bearbeiten Sie diese Aufgaben nur, falls Sie am Praktikum für 6 ECTS-Punkte teilnehmen, jedoch nicht, falls Sie am Praktikum für 3 ECTS-Punkte teilnehmen.\n",
    "### Anti-Monotone Constraints\n",
    "- In der Vorlesung haben Sie anti-monotone Constraints zur Einschränkung der relevanten Itemsets kennengelernt.\n",
    "- Implementieren Sie eine Möglichkeit, mittels des Parameters *prices* ein Dictionary mitzugeben, welches die Preise der einzelnen Items mitgibt.\n",
    "- Durch den Parameter *max_price* soll dann eine mögliche Preisgrenze gegeben werden. Das heißt, es sollen nur frequent Itemsets zurückgegeben werden, welche nicht mehr als *max_price* kosten. Falls *max_price* den Wert None hat, soll der Constraint des maximalen Preises nicht genutzt werden.\n",
    "- Nutzen Sie die Anti-Monotonie des Constraints aus, um die Generierung unnötiger Kandidaten zu vermeiden. Es ist NICHT ausreichend, alle frequent Itemsetzs erst zu berechnen um dann ganz zum Schluss die \"zu teuren\" zu entfernen!\n",
    "\n",
    "### Konfidenz und Interessantheit\n",
    "- Der Apriorie Algorithmus liefert Ihnen die Frequent Itemsets und ihren Support. Berechnen Sie aus diesen die Assoziationsregeln, welche eine vorgegebene Konfidenz überschreiten.\n",
    "- Implementieren Sie die Funktion *interestingness* so, dass sie die Assozationsregeln, welche eine gewisse Konfidenz überschreiten und deren Interessantheit zurückgeben!\n",
    "- **Hinweis**: Überlegen Sie sich, wie Sie die (teure!) Berechnung aller Teilmengen eines Itemsets vermeiden können. Vielleicht haben Sie diese zu dieesm Zeitpunkt schon als Teil einer Liste/Menge vorliegen?\n",
    "\n",
    "## Erinnerung\n",
    "Bitte vergessen Sie nicht, sich offiziell im Praktikum einzuschreiben! Sollten Sie Fragen dazu haben, wenden Sie sich bitte per E-Mail an hille@cs.uni-kassel.de."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten laden\n",
    "Diesen Teil bitte nicht verändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T14:20:16.576556300Z",
     "start_time": "2023-12-13T14:20:16.537542800Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "with open(\"warenkorb.csv\") as f:\n",
    "    data = []\n",
    "    for line in f.readlines():\n",
    "        items = [item.strip() for item in line.split(\",\")]\n",
    "        items.sort()\n",
    "        data.append(items)\n",
    "data\n",
    "prices = {\n",
    "    \"Chips\": 2.5,\n",
    "    \"Bier\": 5,\n",
    "    \"TV-Zeitschrift\": 2,\n",
    "    \"Windeln\": 1.5,\n",
    "    \"Zahnpasta\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementierung\n",
    "Implementieren Sie in diesem Teil Ihre Lösung. Die gegebenen Datenstrukturen und Methoden können Sie als Hilfestellung (insbesondere für eine effiziente Lösung) benutzen, müssen Sie aber nicht. Nur die Apriori-Methode sollte so funktionieren wie  gegeben. Sie können natürlich weitere Methoden hinzufügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T14:30:25.743934100Z",
     "start_time": "2023-12-13T14:30:25.714531200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({['Chips']: 0.75,\n",
       "         ['Bier']: 0.625,\n",
       "         ['TV-Zeitschrift']: 0.5,\n",
       "         ['Chips', 'TV-Zeitschrift']: 0.5,\n",
       "         ['Windeln']: 0.375,\n",
       "         ['Bier', 'Chips']: 0.375,\n",
       "         ['Bier', 'Windeln']: 0.375,\n",
       "         ['Zahnpasta']: 0.25,\n",
       "         ['Bier', 'TV-Zeitschrift']: 0.25,\n",
       "         ['Bier', 'Chips', 'TV-Zeitschrift']: 0.25,\n",
       "         ['Chips', 'Windeln']: 0.125,\n",
       "         ['Windeln', 'Zahnpasta']: 0.125,\n",
       "         ['Bier', 'Zahnpasta']: 0.125,\n",
       "         ['Chips', 'Zahnpasta']: 0.125,\n",
       "         ['Bier', 'Chips', 'Windeln']: 0.125,\n",
       "         ['Bier', 'Windeln', 'Zahnpasta']: 0.125})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def aprioriCandidateGeneration(l, max_price):\n",
    "    res = set()\n",
    "    \n",
    "    for i in l:\n",
    "        for j in l:\n",
    "            if i == j: continue\n",
    "            # Sammle alle Itemsets die auf den ersten n-1 Elementen gleich sind\n",
    "            if i.eqFirstElements(j):\n",
    "                # Erstelle neue Itemsets der Länge n+1, mit den n-1 gleichen Elementen und den beiden letzten der Itemsets\n",
    "                t = i.join(j)\n",
    "                # Nehme nur Itemsets aud deren n-1 letzte Elemente in den Itemsets der Länge n-1 liegen und maxPrice nicht überschreiten\n",
    "                if t.items[1:] in [k.items for k in l] and sum(prices[i] for i in t.items) <= max_price:\n",
    "                    res.add(t)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def freqItems(transactions, candidates, minSup):\n",
    "    res = []\n",
    "    counter = Counter()\n",
    "\n",
    "    # Zähle wie oft die Itemsets in den Transaktionen vorkommen\n",
    "    for i in transactions:\n",
    "        for j in candidates:\n",
    "            if set(j.items).issubset(set(i)):\n",
    "                if j not in counter:\n",
    "                    counter[j] = 1\n",
    "                else:\n",
    "                    counter[j] += 1\n",
    "\n",
    "    # Sammle alle Itemsets mit dem minimal Support\n",
    "    for c in counter.copy():\n",
    "        support = counter[c] / len(transactions)\n",
    "        if support >= minSup:\n",
    "            counter[c] = support\n",
    "            res.append(c)\n",
    "        else:\n",
    "            del counter[c]\n",
    "\n",
    "    return res, counter\n",
    "\n",
    "\n",
    "def apriori(transactions, prices=prices, max_price=None, minsup=0.01):\n",
    "    # The parameters prices and max_price are just needed for 6ECTS!\n",
    "    res = []\n",
    "    counter = Counter()\n",
    "    if max_price is None: max_price = np.inf\n",
    "    \n",
    "    # Berechne ein elementige frequent Itemsets\n",
    "    l, c  = freqItems(transactions, set(Itemset([i]) for i in set(item for t in transactions for item in t)), minsup)\n",
    "    res.append(l)\n",
    "    counter.update(c)\n",
    "\n",
    "    # Berechne ein mehrelementige frequent Itemsets\n",
    "    while l:\n",
    "        candidates = aprioriCandidateGeneration(l, max_price)\n",
    "        l, c = freqItems(transactions, candidates, minsup)\n",
    "        res.append(l)\n",
    "        counter.update(c)\n",
    "\n",
    "    return counter\n",
    "\n",
    "\n",
    "def extendRules(temp, l, min_conf):\n",
    "    # Kreiere neue Regeln aus der Vereinigung der linken Seiten; und dem Schnitt der rechten Seiten\n",
    "    res = Counter()\n",
    "\n",
    "    while len(list(temp.keys())[0][0].items) > 1: #Regel bei denen die lineke Regelseite ein Element hat sind fertig\n",
    "    \n",
    "        tempL = [i for i in temp]\n",
    "        temp = {}\n",
    "        \n",
    "        for i in range(0, len(tempL)-1):\n",
    "            for j in range(i+1, len(tempL)):\n",
    "                leftSide, rightSide = tempL[i][0].intersection(tempL[j][0]) , tempL[i][1].union(tempL[j][1])\n",
    "                conf = l[leftSide]/l[rightSide]\n",
    "                interestingness = l[leftSide.union(rightSide)]/l[leftSide] - l[rightSide]\n",
    "                if conf >= min_conf:\n",
    "                    res[leftSide, rightSide] = interestingness\n",
    "                    temp[leftSide, rightSide] = interestingness\n",
    "    return res\n",
    "            \n",
    "    \n",
    "            \n",
    "\n",
    "def interestingness(l, min_conf):\n",
    "    r\"\"\"\n",
    "    This function is only needed for 6ECTS!\n",
    "    The list l contains all frequent itemsets and their support.\n",
    "    Compute fom all frequent Itemsets X and all their subsets A the interestingness of the rule\n",
    "    A -> X\\A if this rule has at least the confidence min_conf.\n",
    "    Returns a list of tuples where each tuple has the form (A, X\\A , interstingness of A -> X\\A)\n",
    "    \"\"\"\n",
    "    res = Counter()\n",
    "    temp = {}\n",
    "    leftSide, rightSide = [], []\n",
    "    \n",
    "    for i in l:\n",
    "        if len(i.items) == 1: continue\n",
    "        # Berechne alle Regeln mit einelementiger rechter Regelseite\n",
    "        for j in range(len(i.items)):\n",
    "            leftSide, rightSide = Itemset(i.items[:j] + i.items[j+1:]) , Itemset([i.items[j]])\n",
    "            conf = l[leftSide]/l[rightSide]\n",
    "            interestingness = l[leftSide.union(rightSide)]/l[leftSide] - l[rightSide]\n",
    "            if conf >= min_conf:\n",
    "                temp[leftSide, rightSide] = interestingness\n",
    "                res[leftSide, rightSide] = interestingness\n",
    "\n",
    "        res.update(extendRules(temp, l, min_conf))\n",
    "        temp = {}\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "class Itemset:\n",
    "    \"\"\"A hashable itemset that can be used as a key in dictionaries or as an element in sets.\n",
    "    You can change this class how ever you like.\"\"\"\n",
    "\n",
    "    def __init__(self, items):\n",
    "        items.sort()\n",
    "        self.items = items\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.items)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return len(self.items) == len(other.items) and set(\n",
    "            self.items).issubset(other.items)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(str(self))\n",
    "\n",
    "    def join(self, other):\n",
    "        t = self.items[0:-1] + [self.items[-1]] + [other.items[-1]]\n",
    "        return Itemset(t)\n",
    "\n",
    "    def eqFirstElements(self, other):\n",
    "        return self.items[0:-1] == other.items[0:-1]\n",
    "    \n",
    "    def union(self, other):\n",
    "        t = list(set(self.items).union(set(other.items)))\n",
    "        return Itemset(t)\n",
    "\n",
    "    def intersection(self, other):\n",
    "        t = list(set(self.items).intersection(set(other.items)))\n",
    "        return Itemset(t)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate frequent itemsets for the given data-set and print the result.\n",
    "items = apriori(data, minsup=0.1)\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests für die 6ECTS Aufgaben\n",
    "Löschen Sie die folgenden Zellen, wenn Sie nur 3ECTS benötigen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T14:30:26.674271700Z",
     "start_time": "2023-12-13T14:30:26.662724900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({['Chips']: 0.75,\n",
       "         ['Bier']: 0.625,\n",
       "         ['TV-Zeitschrift']: 0.5,\n",
       "         ['Chips', 'TV-Zeitschrift']: 0.5,\n",
       "         ['Windeln']: 0.375,\n",
       "         ['Bier', 'Windeln']: 0.375,\n",
       "         ['Zahnpasta']: 0.25,\n",
       "         ['Bier', 'TV-Zeitschrift']: 0.25})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_sets = apriori(data, minsup=0.2, max_price=7)\n",
    "item_sets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T14:30:27.344244700Z",
     "start_time": "2023-12-13T14:30:27.245373100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({(['Bier', 'Zahnpasta'], ['Windeln']): 0.625,\n",
       "         (['Windeln'], ['Bier']): 0.375,\n",
       "         (['TV-Zeitschrift'], ['Chips']): 0.25,\n",
       "         (['Bier', 'TV-Zeitschrift'], ['Chips']): 0.25,\n",
       "         (['Bier'], ['Windeln']): 0.22499999999999998,\n",
       "         (['Chips'], ['TV-Zeitschrift']): 0.16666666666666663,\n",
       "         (['Bier', 'Chips'], ['TV-Zeitschrift']): 0.16666666666666663,\n",
       "         (['Zahnpasta'], ['Windeln']): 0.125,\n",
       "         (['TV-Zeitschrift'], ['Bier', 'Chips']): 0.125,\n",
       "         (['Windeln'], ['Zahnpasta']): 0.08333333333333331,\n",
       "         (['Chips'], ['Bier', 'TV-Zeitschrift']): 0.08333333333333331,\n",
       "         (['Bier', 'Windeln'], ['Zahnpasta']): 0.08333333333333331,\n",
       "         (['Bier'], ['Chips', 'Windeln']): 0.07500000000000001,\n",
       "         (['Bier'], ['Windeln', 'Zahnpasta']): 0.07500000000000001,\n",
       "         (['Bier', 'Chips'], ['Windeln']): -0.041666666666666685,\n",
       "         (['Bier'], ['Zahnpasta']): -0.04999999999999999,\n",
       "         (['Chips'], ['Zahnpasta']): -0.08333333333333334,\n",
       "         (['Bier'], ['TV-Zeitschrift']): -0.09999999999999998,\n",
       "         (['Bier'], ['Chips', 'TV-Zeitschrift']): -0.09999999999999998,\n",
       "         (['Chips'], ['Bier']): -0.125,\n",
       "         (['TV-Zeitschrift'], ['Bier']): -0.125,\n",
       "         (['Zahnpasta'], ['Bier']): -0.125,\n",
       "         (['Chips', 'TV-Zeitschrift'], ['Bier']): -0.125,\n",
       "         (['Bier'], ['Chips']): -0.15000000000000002,\n",
       "         (['Chips'], ['Windeln']): -0.20833333333333334,\n",
       "         (['Zahnpasta'], ['Chips']): -0.25,\n",
       "         (['Windeln'], ['Chips']): -0.4166666666666667,\n",
       "         (['Bier', 'Windeln'], ['Chips']): -0.4166666666666667})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_sets = apriori(data, minsup=0.01)\n",
    "i = interestingness(item_sets, min_conf=0.3)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T14:08:18.042672500Z",
     "start_time": "2023-12-13T14:08:18.037134200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
