{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation mit *k*-Nearest-Neighbors\n",
    "Ziel dieser Übung ist das eigenständige Implementieren des Klassifikations-Algorithmus *k*-Nearest-Neighbors innerhalb des Jupyter-Notebooks. Implementieren sie folgende Variante des *k*-Nearest-Neighbors:\n",
    "- Alle Attribute sind vor der Benutzung auf den Wertebereich $[0;1]$ zu normieren. Beachten Sie dabei, dass für das \"Training\" des Klassifikators keine Informationen aus den Testdaten verwendet werden dürfen.\n",
    "- Als Distanzfunktion nutzen Sie bitte die euklidische Distanz.\n",
    "- Für das Abstimmen der *k* nächsten Nachbarn soll es vier Varianten geben, die mittels eines Parameters an die Klasse übergeben werden können:\n",
    "    1. Eine einfache Mehrheitsabstimmung unter den Nachbarn\n",
    "    2. Jeder Nachbar wird mit dem inversen Quadrat der Distanz gewichtet.\n",
    "    3. Die Stimmen einer Klasse werden mit dem Inversen ihrer Durchschnittsdistanz gewichtet.\n",
    "    4. Eine Mehrheitsabstimmung gewichtet nach der Verteilung der Klassen.\n",
    "   \n",
    "Sie dürfen die Pakete **collections**, **math** und **numpy** für Ihre Implementierung nutzen. Für die Ausführung der Tests benötigen Sie außerdem **pandas**.\n",
    "\n",
    "# Aufgaben für 6ECTS\n",
    "Der *k*-nearest Neighbor Algorithmus verwendet für die Klassifikation verschiedene Parameter: Es muss ein fester Wert für **k** und eine der Entscheidungsstrategien gewählt werden. Doch wie wählt man die Parameter sinnvoll? Eine Möglichkeit liefert die Kreuzvalidierung, welche Sie implementieren sollen:\n",
    "Die Funktion *train* hat einen Parameter **ks**. Falls dieser nicht *None* ist, soll dieser Parameter genutzt werden, um eine Liste von Möglichen *k* Werten zu übergeben. Sie sollen dann wie folgt vorgehen, um aus dieser Liste von *k* Werten das bestmögliche *k* und die bestmögliche der 4 Strategien zu wählen:\n",
    "- Teilen Sie die Daten zufällig in 5 gleichgroße Teile auf. Nutzen Sie dafür die vorgegebene Funktion *split*.\n",
    "- Gehen Sie für jedes Kombination für *k* und jeder Stratege *s* wie folgt vor um die besten Werte zu finden:\n",
    "- Für jede der 5 Datensatzteile \"trainieren\" sie auf den üblichen 4 Teilen und klassifizieren die Daten des nicht zum Training verwendeten Teil. Zählen Sie die richtigen Klassifikationen.\n",
    "- Summieren Sie auf, sodass sie die richtigen Entscheidungen über alle 5 Teile erhalten.\n",
    "- Nun haben sie für jedes Paar (*k*,*s*) eine Anzahl an richtigen Entscheidungen über die 5 Teile.\n",
    "- Wählen Sie nun die beste Kombination aus und \"trainieren\" sie auf den ganzen Datensatz. Speichern Sie außerdem das \"beste\" Paar (*k*,*s*).\n",
    "- Wird nun die Funktion *predict* mit *best_combination=True* aufgerufen, so sollen der ermittelte Wert für *k* und die ermittelte Strategie statt die übergebenen Werte genutzt werden.\n",
    "\n",
    "\n",
    "Damit die Aufgabe als sinnvoll bearbeitet gilt, sind folgende Anforderungen zu erfüllen:\n",
    "- Bei einem Durchlauf durch den Iris-Datensatz sollen keine Ausführungsfehler bestehen und (sehr) gute Werte für die Accuracy geliefert werden.\n",
    "- Abgabe der Übung bis 26.01.2024 23:59 Uhr im Moodle-Kurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:21:44.693557111Z",
     "start_time": "2024-01-25T11:21:44.514723210Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import random  # Just needed for 6ECTS\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    \"\"\"Calculate the euclidian distance.\"\"\"\n",
    "    return np.linalg.norm(x - y)\n",
    "\n",
    "\n",
    "def split(data, labels, n=5):\n",
    "    \"\"\"Split the training points and labels into 5 equal sized parts. Just needed for 6 ECTS.\"\"\"\n",
    "    m = list(range(len(data)))\n",
    "    random.shuffle(m)\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    indices = [np.array(m[i::n]) for i in range(n)]\n",
    "    data = [data[i].tolist() for i in indices]\n",
    "    labels = [labels[i].tolist() for i in indices]\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "class KNN:\n",
    "\n",
    "    def __init__(self, dist_fun=euclidean_dist):\n",
    "        self.dist_fun = dist_fun\n",
    "        self.trainData = []\n",
    "        self.trainLabels = []\n",
    "        self.classifier = {}\n",
    "        self.k = 0\n",
    "        self.strategy = \"\"\n",
    "        self.strategies = [\n",
    "            \"majority\",\n",
    "            \"inverse_squared_distance\",\n",
    "            \"inverse_avg_distance\",\n",
    "            \"distribution\",\n",
    "        ]\n",
    "\n",
    "    def train(self, data, labels, ks=None):\n",
    "        \"\"\"Train this classifier. Takes a list of samples data and a list of class-labels labels.\n",
    "        Each sample is a list of numeric values. Each label is a string.\n",
    "        The parameter ks ist just needed for 6ECTS.\n",
    "        \"\"\"\n",
    "        assert len(data) == len(labels)\n",
    "        data = self.normalize(data)\n",
    "\n",
    "        self.trainData = data\n",
    "        self.trainLabels = labels\n",
    "\n",
    "        # Find optimal parameters\n",
    "        if ks:\n",
    "            bestCombination = (0, \"\", 0) # k, strategy, quality\n",
    "            data, labels = split(data, labels)\n",
    "            i = random.randint(0, 4)\n",
    "            self.trainData = np.concatenate([data[j] for j in range(5) if j != i])\n",
    "            self.trainLabels = np.concatenate([labels[j] for j in range(5) if j != i])\n",
    "            testData = data[i]\n",
    "            testLabels = labels[i]\n",
    "\n",
    "            for k in ks:\n",
    "                for s in self.strategies:\n",
    "                    predLabels = self.predict(testData, k, s)\n",
    "                    countDiff = sum(x == y for x, y in zip(predLabels, testLabels))\n",
    "                    bestCombination = (k, s, countDiff) if countDiff > bestCombination[2] else bestCombination\n",
    "\n",
    "            self.k, self.strategy = bestCombination[0], bestCombination[1]\n",
    "\n",
    "    def predict(self, data, k=3, strategy=\"majority\", best_combination=False):\n",
    "        \"\"\"Takes a list of samples data. Returns a list of predicted labels for the samples.\n",
    "        The parameter best_combination ist just needed for 6ECTS.\n",
    "        \"\"\"\n",
    "        data = self.normalize(data)\n",
    "        if best_combination:\n",
    "            k, strategy = self.k, self.strategy\n",
    "        return [self.predict_sample(data, k, strategy) for data in data]\n",
    "\n",
    "    def predict_sample(self, data, k=3, strategy=\"majority\"):\n",
    "        \"\"\"Predicts the label for a single sample data.\"\"\"\n",
    "        distances = [euclidean_dist(data, sample) for sample in self.trainData]\n",
    "        nearestIndices = np.argsort(distances)[:k]\n",
    "        nearest = {distances[i]: self.trainData[i] for i in nearestIndices}  #distances:vector\n",
    "        nearestLabels = [self.trainLabels[i] for i in nearestIndices]\n",
    "        res = Counter({label: 0 for label in set(self.trainLabels)})\n",
    "\n",
    "        match strategy:\n",
    "\n",
    "            # classic k-nn\n",
    "            case \"majority\":\n",
    "\n",
    "                return Counter(nearestLabels).most_common()[0][0]\n",
    "\n",
    "            # weighted by the inverse square of each neighbor\n",
    "            case \"inverse_squared_distance\":\n",
    "\n",
    "                for i, k in enumerate(nearest):\n",
    "                    res[nearestLabels[i]] += (1 / (k ** 2))\n",
    "                return res.most_common()[0][0]\n",
    "\n",
    "            # weighted by the inverse average distance of each class\n",
    "            case \"inverse_avg_distance\":\n",
    "\n",
    "                weights = {label: 0 for label in set(self.trainLabels)}\n",
    "                count = {label: 0 for label in set(self.trainLabels)}\n",
    "\n",
    "                for i in range(len(self.trainLabels)):\n",
    "                    weights[self.trainLabels[i]] += distances[i]\n",
    "                    count[self.trainLabels[i]] += 1\n",
    "                for key in weights.keys():\n",
    "                    weights[key] = 1 / (weights[key] / count[key])\n",
    "                for i, k in enumerate(nearest):\n",
    "                    res[nearestLabels[i]] += weights[nearestLabels[i]]\n",
    "                return res.most_common()[0][0]\n",
    "\n",
    "            # weighted by distribution of classes\n",
    "            case \"distribution\":\n",
    "\n",
    "                weights = Counter(self.trainLabels)\n",
    "\n",
    "                for i, k in enumerate(nearest):\n",
    "                    res[nearestLabels[i]] += (weights[nearestLabels[i]] / len(self.trainLabels))\n",
    "                return res.most_common()[0][0]\n",
    "\n",
    "    def normalize(self, data):\n",
    "        \"\"\"Normalize data of each attribute\"\"\"\n",
    "        data = np.array(data)\n",
    "        return data / data.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluierung des Klassifikators\n",
    "Mit diesem Code können Sie Ihre Implementierung anhand des mitgelieferten IRIS-Datensatzes testen. Probieren Sie auch verschiedene (sinnvolle) Werte für den Parameter *k*. Bitte ansonsten in diesem Teil nichts mehr ändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:21:44.768260762Z",
     "start_time": "2024-01-25T11:21:44.662722174Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    \"\"\"Calculates the accuracy for the given class predictions and true classes.\"\"\"\n",
    "    assert len(predictions) == len(targets)\n",
    "    n_correct = len([p for p, t in zip(predictions, targets) if p == t])\n",
    "    return n_correct / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:21:44.811064058Z",
     "start_time": "2024-01-25T11:21:44.707964960Z"
    }
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(predictions, targets):\n",
    "    \"\"\"Returns a tuple (labels, m) where m is the confusion matrix and\n",
    "    labels is the list of matrix rows/columns in same order as in the matrix.\n",
    "    Rows in the confusion matrix indicate the true target label\n",
    "    whereas the columns indicate the predicted label of samples.\n",
    "    \"\"\"\n",
    "    assert len(predictions) == len(targets)\n",
    "\n",
    "    # Map each label to an index.\n",
    "    unique_vals = list(set(predictions).union(targets))\n",
    "    mapping = {label: index for index, label in enumerate(unique_vals)}\n",
    "\n",
    "    # Build and fill the confusion matrixdata.\n",
    "    m = [[0] * len(mapping) for _ in range(len(mapping))]\n",
    "    for p, t in zip(predictions, targets):\n",
    "        row, col = mapping[t], mapping[p]\n",
    "        m[row][col] += 1\n",
    "    return unique_vals, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:21:45.183357336Z",
     "start_time": "2024-01-25T11:21:44.846165429Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the csv and drop duplicate entries.\n",
    "data = pd.read_csv(\"iris.csv\").drop_duplicates()\n",
    "\n",
    "# Draw a random sample without replacement for the test data.\n",
    "test_data = data.sample(n=50)\n",
    "\n",
    "# The other samples are used as training data.\n",
    "train_data = data.loc[data.index.drop(test_data.index), :]\n",
    "\n",
    "\n",
    "def df_to_vectors(df):\n",
    "    \"\"\"Take a pandas data-frame from the iris dataset as input.\n",
    "    Returns a tuple (data, labels) where labels is a list of class labels\n",
    "    and data is the list of sample-vectors\n",
    "    with each vector represented as a list of numeric values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    classes = df[\"species\"]\n",
    "    del df[\"species\"]\n",
    "    return df.values.tolist(), classes.values.tolist()\n",
    "\n",
    "\n",
    "# Convert train and test-data to lists of vectors and class labels.\n",
    "data_train, labels_train = df_to_vectors(train_data)\n",
    "data_test, labels_test = df_to_vectors(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:21:45.533612046Z",
     "start_time": "2024-01-25T11:21:45.026220784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of strategy majority: 0.96\n",
      "Confusion matrix:\n",
      "[13, 0, 0]\n",
      "[2, 17, 0]\n",
      "[0, 0, 18]\n",
      "----------\n",
      "Accuracy of strategy inverse_squared_distance: 0.94\n",
      "Confusion matrix:\n",
      "[13, 0, 0]\n",
      "[3, 16, 0]\n",
      "[0, 0, 18]\n",
      "----------\n",
      "Accuracy of strategy inverse_avg_distance: 0.96\n",
      "Confusion matrix:\n",
      "[13, 0, 0]\n",
      "[2, 17, 0]\n",
      "[0, 0, 18]\n",
      "----------\n",
      "Accuracy of strategy distribution: 0.96\n",
      "Confusion matrix:\n",
      "[13, 0, 0]\n",
      "[2, 17, 0]\n",
      "[0, 0, 18]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "clf = KNN()\n",
    "clf.train(data_train, labels_train)\n",
    "for strategy in clf.strategies:\n",
    "    predictions = clf.predict(data_test, strategy=strategy, k=3)\n",
    "    print(\"Accuracy of strategy {}: {}\".format(\n",
    "        strategy, accuracy(predictions, labels_test)))\n",
    "    labels, matrix = confusion_matrix(predictions, labels_test)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(\"\\n\".join([str(row) for row in matrix]))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the following Lines if you just need 3 ECTS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:21:45.882957968Z",
     "start_time": "2024-01-25T11:21:45.401136363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination:\n",
      "k: 1\n",
      "strategy: majority\n",
      "-----------\n",
      "Accuracy 0.96\n",
      "Confusion matrix:\n",
      "[13, 0, 0]\n",
      "[2, 17, 0]\n",
      "[0, 0, 18]\n"
     ]
    }
   ],
   "source": [
    "clf = KNN()\n",
    "clf.train(data_train, labels_train, ks=[1, 3, 5, 7])\n",
    "print(\"Best combination:\")\n",
    "print(\"k:\", clf.k)\n",
    "print(\"strategy:\", clf.strategy)\n",
    "print(\"-----------\")\n",
    "predictions = clf.predict(data_test, best_combination=True)\n",
    "labels, matrix = confusion_matrix(predictions, labels_test)\n",
    "print(\"Accuracy {}\".format(accuracy(predictions, labels_test)))\n",
    "print(\"Confusion matrix:\")\n",
    "print(\"\\n\".join([str(row) for row in matrix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:21:45.884624534Z",
     "start_time": "2024-01-25T11:21:45.866574453Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
